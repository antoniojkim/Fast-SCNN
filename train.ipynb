{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model.FastSCNN import *\n",
    "from Dataset.dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from yaml import load, dump\n",
    "try:\n",
    "    from yaml import CLoader as Loader, CDumper as Dumper\n",
    "except ImportError:\n",
    "    from yaml import Loader, Dumper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters\n",
    "\n",
    "The parameters are read from a [yaml](https://en.wikipedia.org/wiki/YAML) file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_path': '/mnt/sda/datasets/Audi/roadline',\n",
       " 'crop_height': 960,\n",
       " 'crop_width': 1920}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"params.yml\") as file:\n",
    "    params = load(file, Loader=Loader)\n",
    "    \n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required\n",
    "dataset_path = params[\"dataset_path\"]   # Path at which the dataset is located\n",
    "crop_height  = params[\"crop_height\"]    # Height of cropped/resized input image\n",
    "crop_width   = params[\"crop_width\"]     # Width of cropped/resized input image\n",
    "\n",
    "# optional\n",
    "num_epochs            = params.get(\"num_epochs\", 100)                   # Number of epochs to train for\n",
    "epoch_start           = params.get(\"epoch_start\", 0)                    # Start counting epochs from this number\n",
    "batch_size            = params.get(\"batch_size\", 2)                     # Number of images in each batch\n",
    "checkpoint_step       = params.get(\"checkpoint_step\", 2)                # How often to save checkpoints (epochs)\n",
    "validation_step       = params.get(\"validation_step\", 2)                # How often to perform validation (epochs)\n",
    "learning_rate         = params.get(\"learning_rate\", 0.01)               # learning rate used for training\n",
    "cuda                  = params.get(\"cuda\", \"0,1\")                       # GPU ids used for training  \n",
    "use_gpu               = params.get(\"use_gpu\", True)                     # whether to user gpu for training\n",
    "pretrained_model_path = params.get(\"pretrained_model_path\", None)       # path to pretrained model\n",
    "save_model_path       = params.get(\"save_model_path\", \"./checkpoints\")  # path to save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if crop_height * 2 != crop_width:\n",
    "    raise AssertionError(\"Crop width must be exactly twice the size of crop height\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if all required paths are present\n",
    "if not os.path.join(dataset_path, \"class_dict.csv\"):\n",
    "    raise AssertionError(os.path.join(dataset_path, \"class_dict.csv\") + \" does not exist\")\n",
    "\n",
    "for directory in (\"train\", \"train_labels\", \"test\", \"test_labels\", \"val\", \"val_labels\"):\n",
    "    if not os.path.isdir(os.path.join(dataset_path, directory)):\n",
    "        raise AssertionError(os.path.join(dataset_path, directory) + \" does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(dataset_path, crop_height, crop_width, mode=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastSCNN(image_height   = crop_height,\n",
    "                 image_width    = crop_width,\n",
    "                 image_channels = 3,\n",
    "                 num_classes    = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1136245"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_parameters = sum(p.numel() for p in model.parameters())\n",
    "num_parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (watonomous)",
   "language": "python",
   "name": "watonomous"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
