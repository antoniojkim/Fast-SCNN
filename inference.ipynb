{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import imageio\n",
    "    \n",
    "import torchx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FastSCNN import AudiDataset, FastSCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torchx.params.Parameters(\"params.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2 if params.single_class else len(AudiDataset.classes)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastSCNN(image_height   = params.crop_height,\n",
    "                 image_width    = params.crop_width,\n",
    "                 image_channels = 3,\n",
    "                 num_classes    = num_classes).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load(\"checkpoints/latest_half_scale_single_class_fastscnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = AudiDataset(\n",
    "    params.crop_height,\n",
    "    params.crop_width,\n",
    "    params.resize_scale, \n",
    "    mode=\"test\",\n",
    "    single_class = params.single_class,\n",
    "    normalization_mean = (0.485, 0.456, 0.406),\n",
    "    normalization_std = (0.229, 0.224, 0.225),\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size  = 1,\n",
    "    num_workers = 4,\n",
    "    shuffle     = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_plot(image, label, figsize = (18, 10)):\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "\n",
    "    fig, ax = plt.subplots(2, 2, figsize=figsize)\n",
    "\n",
    "    denormalized = np.moveaxis(np.array(test_dataset.denormalize(image[0])), 0, -1)\n",
    "#     print(denormalized.min(), denormalized.max())\n",
    "    ax[0, 0].imshow(denormalized)\n",
    "    ax[0, 0].set_title(\"Original Image (Rescaled)\")\n",
    "\n",
    "    normalized = np.moveaxis(image[0].detach().numpy(), 0, -1)\n",
    "#     normalized = (normalized - normalized.min()) / (normalized.max() - normalized.min())\n",
    "#     print(normalized.min(), normalized.max(), normalized.shape)\n",
    "    ax[0, 1].imshow(normalized)\n",
    "    ax[0, 1].set_title(\"Normalized Image\")\n",
    "\n",
    "    ax[1, 0].imshow(torchx.utils.decode_array(label[0].detach().numpy(), test_dataset.class_list))\n",
    "    ax[1, 0].set_title(\"Labels\")\n",
    "\n",
    "    ax[1, 1].imshow(torchx.utils.decode_array(output[0].argmax(axis=0), test_dataset.class_list))\n",
    "    ax[1, 1].set_title(\"Model Prediction\")\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "# fig, ax = generate_plot(image, label)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n",
      "0.0 1.0\n",
      "0.0 1.0 (480, 960, 3)\n"
     ]
    }
   ],
   "source": [
    "def generate_gif(num_image = 50):\n",
    "    with imageio.get_writer('examples/fastscnn.gif', mode='I', duration=0.5) as writer:\n",
    "\n",
    "        for i, (image, label) in enumerate(test_dataloader):\n",
    "\n",
    "            fig, ax = generate_plot(image, label, (12, 7))\n",
    "\n",
    "            fig.tight_layout()\n",
    "\n",
    "            filename = f\"examples/{test_dataset.get_path(i)[0].split('/')[-1]}\"\n",
    "            plt.savefig(filename, bbox_inches=\"tight\")\n",
    "            plt.close()\n",
    "\n",
    "            writer.append_data(imageio.imread(filename))\n",
    "\n",
    "            if i >= num_images:\n",
    "                break\n",
    "            \n",
    "generate_gif(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hist(a, b, n):\n",
    "\tk = (a >= 0) & (a < n)\n",
    "\treturn np.bincount(n * a[k].astype(int) + b[k], minlength=n ** 2).reshape(n, n)\n",
    "\n",
    "iou_per_class = lambda hist: (np.diag(hist) + 1e-5) / (hist.sum(1) + hist.sum(0) - np.diag(hist) + 1e-5)\n",
    "\n",
    "def run_test():\n",
    "\n",
    "    with torch.no_grad(), tqdm(total=len(test_dataloader), position=0, leave=False) as val_progress:\n",
    "        model.eval()\n",
    "    \n",
    "        val_progress.set_description('testing')\n",
    "        \n",
    "        precisions = []\n",
    "        hist = np.zeros((num_classes, num_classes))\n",
    "\n",
    "        for i, (data, label) in enumerate(test_dataloader):\n",
    "                            \n",
    "            output = model(data).squeeze()\n",
    "            output = reverse_one_hot(output)\n",
    "            output = np.array(output)\n",
    "\n",
    "            label = label.squeeze()\n",
    "            label = np.array(label)\n",
    "\n",
    "            precisions.append(np.sum(output == label) / np.prod(label.shape))\n",
    "            hist += compute_hist(output.flatten(), label.flatten(), num_classes)\n",
    "            \n",
    "            val_progress.set_postfix(precision='%.6f' % np.mean(precisions))\n",
    "            val_progress.update()\n",
    "        \n",
    "        precision = np.mean(precisions)\n",
    "        iou = iou_per_class(hist)[:-1]\n",
    "        miou = np.mean(iou)\n",
    "    \n",
    "    return precision, miou, iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    }
   ],
   "source": [
    "precision, miou, iou = run_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9874482929218613"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5797625302831695"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98782668, 0.47653893, 0.40126869, 0.45341582])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achieved precision of 0.9874482929218613\n",
    "\n",
    "Achieved miou of 0.5797625302831695\n",
    "\n",
    "iou per class: [0.98782668, 0.47653893, 0.40126869, 0.45341582]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.randn(\n",
    "    1,\n",
    "    3,\n",
    "    int(params.crop_height * params.resize_scale),\n",
    "    int(params.crop_width * params.resize_scale),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.1 ms ± 107 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "with torch.no_grad():\n",
    "    label = model(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
